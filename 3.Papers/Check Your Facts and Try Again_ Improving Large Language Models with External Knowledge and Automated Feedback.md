
- **PublishYear**:: 2023 
- **Author**:: Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, Jianfeng Gao
- **Link**:: http://arxiv.org/abs/2302.12813
- **Tags**:: #paper #LLM 
- **Cite Key**:: [@pengCheckYourFacts2023]

### Abstract
```
Large language models (LLMs), such as ChatGPT, are able to generate human-like, fluent responses for many downstream tasks, e.g., task-oriented dialog and question answering. However, applying LLMs to real-world, mission-critical applications remains challenging mainly due to their tendency to generate hallucinations and their inability to use external knowledge. This paper proposes a LLM-Augmenter system, which augments a black-box LLM with a set of plug-and-play modules. Our system makes the LLM generate responses grounded in external knowledge, e.g., stored in task-specific databases. It also iteratively revises LLM prompts to improve model responses using feedback generated by utility functions, e.g., the factuality score of a LLM-generated response. The effectiveness of LLM-Augmenter is empirically validated on two types of scenarios, task-oriented dialog and open-domain question answering. LLM-Augmenter significantly reduces ChatGPT's hallucinations without sacrificing the fluency and informativeness of its responses. We make the source code and models publicly available.
```

### Problems
The knowledge encoding of LLMs is lossy and the knowledge generalization could lead to “memory distortion.”
=> **Hallucinate**

### Solutions
- Augment a fixed LLM with PnP (Plug and Play) modules for mission-critical task.
	=> **LLM-AUGMENTER**: improve LLM with external knowledge and automated feedback 

- Given a user query, LLM-AUGMENTER first retrieves evidence from external knowledge (e.g., Web or task-specific datasets) and, if necessary, further consolidates evidence by linking retrieved raw evidence with related context and performing reasoning to form evidence chains. Then, LLMAUGMENTER queries a fixed LLM  using a prompt that contains the consolidated evidence for ChatGPT to generate a candidate response grounded in external knowledge (evidence). LLM-AUGMENTER then verifies the candidate response e.g., by checking whether it hallucinates evidence. If so, LLM-AUGMENTER generates a feedback message. The message is used to revise the prompt to query ChatGPT again. The process iterates until a candidate response passes the verification and is sent to the user.

### Methodology




---

