@misc{aberdamSequencetoSequenceContrastiveLearning2020,
  title = {Sequence-to-{{Sequence Contrastive Learning}} for {{Text Recognition}}},
  author = {Aberdam, Aviad and Litman, Ron and Tsiper, Shahar and Anschel, Oron and Slossberg, Ron and Mazor, Shai and Manmatha, R. and Perona, Pietro},
  date = {2020-12-20},
  number = {arXiv:2012.10873},
  eprint = {2012.10873},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2012.10873},
  urldate = {2022-12-07},
  abstract = {We propose a framework for sequence-to-sequence contrastive learning (SeqCLR) of visual representations, which we apply to text recognition. To account for the sequence-to-sequence structure, each feature map is divided into different instances over which the contrastive loss is computed. This operation enables us to contrast in a sub-word level, where from each image we extract several positive pairs and multiple negative examples. To yield effective visual representations for text recognition, we further suggest novel augmentation heuristics, different encoder architectures and custom projection heads. Experiments on handwritten text and on scene text show that when a text decoder is trained on the learned representations, our method outperforms non-sequential contrastive methods. In addition, when the amount of supervision is reduced, SeqCLR significantly improves performance compared with supervised training, and when fine-tuned with 100\% of the labels, our method achieves state-of-the-art results on standard handwritten text recognition benchmarks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {files/8/Aberdam et al_2020_Sequence-to-Sequence Contrastive Learning for Text Recognition.pdf;files/9/2012.html}
}

@misc{liuMonolithRealTime2022,
  title = {Monolith: {{Real Time Recommendation System With Collisionless Embedding Table}}},
  shorttitle = {Monolith},
  author = {Liu, Zhuoran and Zou, Leqi and Zou, Xuan and Wang, Caihua and Zhang, Biao and Tang, Da and Zhu, Bolin and Zhu, Yijie and Wu, Peng and Wang, Ke and Cheng, Youlong},
  date = {2022-09-27},
  number = {arXiv:2209.07663},
  eprint = {2209.07663},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2209.07663},
  urldate = {2022-12-07},
  abstract = {Building a scalable and real-time recommendation system is vital for many businesses driven by time-sensitive customer feedback, such as short-videos ranking or online ads. Despite the ubiquitous adoption of production-scale deep learning frameworks like TensorFlow or PyTorch, these general-purpose frameworks fall short of business demands in recommendation scenarios for various reasons: on one hand, tweaking systems based on static parameters and dense computations for recommendation with dynamic and sparse features is detrimental to model quality; on the other hand, such frameworks are designed with batch-training stage and serving stage completely separated, preventing the model from interacting with customer feedback in real-time. These issues led us to reexamine traditional approaches and explore radically different design choices. In this paper, we present Monolith, a system tailored for online training. Our design has been driven by observations of our application workloads and production environment that reflects a marked departure from other recommendations systems. Our contributions are manifold: first, we crafted a collisionless embedding table with optimizations such as expirable embeddings and frequency filtering to reduce its memory footprint; second, we provide an production-ready online training architecture with high fault-tolerance; finally, we proved that system reliability could be traded-off for real-time learning. Monolith has successfully landed in the BytePlus Recommend product.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Retrieval},
  note = {Comment: ORSUM@ACM RecSys 2022},
  file = {files/5/Liu et al_2022_Monolith.pdf;files/6/2209.html}
}
